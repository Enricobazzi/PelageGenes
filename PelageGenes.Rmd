---
title: "PelageGenes"
author: "Enrico"
date: "28 May 2018"
output: html_document
---

# 0. Path Definition

Define the paths to different locations for easier calling during script

```{r Define paths, eval=FALSE, engine='bash'}

ssh -X ebazzicalupo@genomics-b.ebd.csic.es # these analyses will be conducted in server B because the annotated VCF file is located there

Proj_PATH=/home/ebazzicalupo/PelageGenes # path to the project directory
Data_PATH=/home/ebazzicalupo/Data # path to data directory
LPRef_PATH=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23_plus_mt.fa # path to lynx pardinus reference genome file
VCF_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/c_ll_lp_plus_h_ll_aafilled_SNPs_standard_filter.ann.vcf # path to annotated VCF file
gVCF_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/gVCFs # path to gVCFs
BDB_Path=/home/ebazzicalupo/Data/BLASTdatabase # path to BLAST database
DiscBDB_PATH=/home/ebazzicalupo/Data/Discarded_BLASTdatabase # path to Discarded Scaffold BLAST database
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar # path to GATK software

```


# 1. Search for Genes in Lynx pardinus Genome Annotations

Look for the genes names/abbreviations in the genome annotations files. First look in the Lynx pardinus genome annotations. If any are not found, look for them in Felis catus genome annotations [step 2], then in Homo sapiens genome annotations [step 3].

```{r Search in Lynx Annotations, eval=FALSE, engine='bash'}

## A file called PelageGeneList.txt has been prepared with the gene names written for a boolean search through the grep command. Each line is a gene. The file has been located in the project directory (/home/ebazzicalupo/PelageGenes).

## Genome annotation files for the three species have also been copied in the Data directory (/home/ebazzicalupo/Data). The Felis catus and Homo sapiens Genome Annotations have been downloaded from the ensembl website (https://www.ensembl.org/info/data/ftp/index.html).

cd $Proj_PATH

mkdir LynxResults # create directory to store the results for Lynx

GENES=$(cat PelageGeneList.txt) # call all elements of PelageGeneList.txt

IFS=$'\n' # define the end of a line as a separator for elements so that each ENTIRE line in PelageGeneList.txt will be a search entry

# for each gene create a file containing results and move it to results directory
for i in ${GENES[@]}
  do
  grep -i -E "${i}" $Data_PATH/LYPA23C.all.fix.gff3 > ${i}
  mv ${i} LynxResults
done


```

Take the results and find the Parent Gene ID for each. Create a .txt file with the list of all Parent Gene IDs found.

```{r Refine Lynx Results, eval=FALSE, engine='bash'}

cd $Proj_PATH/LynxResults

mkdir ParentIDs # create a directory for storing the Parent Gene ID file

LYNXREFINE=$(ls *) # list all results

# for each result, cut the parent gene ID, sort it, eliminate duplicates and create a .Parent file with the Parent Gene IDs stored inside
for i in ${LYNXREFINE[@]}
  do cut -d ';' -f2 "${i}" | sort -u > "${i}".Parent
  mv "${i}".Parent ParentIDs
done

cd $Proj_PATH/LynxResults/ParentIDs

cat * > ParentIDs.txt # put Parent Gene IDs from all the results in a single .txt file

mv ParentIDs.txt $Proj_PATH

```

# 2. Search in Felis cauts Genome Annotations for Genes not found in Lynx pardinus Genome Annotations. Extract corresponding sequence FASTA. Run BLAST to Lynx pardinus Reference Genome.

Repeat the search in Felis catus genome annotations, using as input the empty results from the Lynx search [step 2a]. This will give coordinates to specific regions in the Felis catus genome.
Use those coordinates to extract the corresponding sequence (.fa) from the Felis catus reference genome [step 2b], and BLAST it to the Lynx pardinus reference genome [step 2c]. Hit results from the BLAST will be analysed individually [step 4], to see if any genes in Lynx pardinus can be added to the Parent Gene ID list for further analyses [steps 5].

## 2a - Search in Cat annotations

```{r Search in Cat Annotations, eval=FALSE, engine='bash'}

cd $Proj_PATH

mkdir CatResults # create directory to store the results for Felis catus

CATGENES=$(wc -l LynxResults/* | grep ' 0 ' | cut -d '0' -f2 | sed 's/ //' | sed 's/LynxResults\///') # List empty results from Lynx search

IFS=$'\n' # define the end of a line as a separator for elements so that each ENTIRE line in PelageGeneList.txt will be a search entry

# for each gene create a file containing results and move it to results directory
for i in $CATGENES; do grep -i -E "${i}" $Data_PATH/Felis_catus.Felis_catus_8.0.92.gff3 > cat_"${i}".gff3; mv cat_"${i}".gff3 CatResults; done

```

## 2b - Generate Cat gene FASTA files for BLAST

```{r Generate Cat gene fasta files for BLAST, eval=FALSE, engine='bash'}

## Reference Genome FASTA files for Felis catus and Homo sapiens have been downloaded from the ensembl website (https://www.ensembl.org/info/data/ftp/index.html) and copied in the Data directory (/home/ebazzicalupo/Data).

cd $Proj_PATH/CatResults

CATREFINE=$(ls cat_*.gff3) # list results from grep search

# for each result from the grep search, create a gene.gff3 file with the non-gene (e.g. mRNA, CDS) strings removed
for i in ${CATREFINE[@]}
  do
  awk -v "key=gene" '$3 == key {print($0)}' ${i} > ${i/.gff3}.gene.gff3
done


CATcoords=$(ls cat_*.gene.gff3) # list gene.gff3 files

# generate FASTA file for each gene.gff3 coordinates file
for i in ${CATcoords[@]}
  do
  bedtools getfasta -fo "${i/.gene.gff3}".fa -fi $Data_PATH/Felis_catus.Felis_catus_8.0.dna_sm.toplevel.fa -bed ${i}
done

```

## 2c - BLAST cat genes to Lynx genome

```{r  BLAST cat genes to Lynx genome, eval=FALSE, engine='bash'}

## First create a BLASTdatabase for the Lynx pardinus FASTA file

cd $Data_PATH

mkdir BLASTdatabase # create a directory for the BLAST database

BDB_Path=/home/ebazzicalupo/Data/BLASTdatabase # define path to BLAST database

scp $LPRef_PATH $BDB_Path # copy reference genome to the BLASTdatabase directory

# create a BLAST database in the BLASTdatabase directory
makeblastdb -in $BDB/lp23_plus_mt.fa -parse_seqids -dbtype nucl

## BLAST each Cat Gene FASTA to the Lynx pardinus Reference Genome and BLAST database. Look at BLAST manual for output options.

cd $Proj_PATH/CatResults

IFS=$'\n'

CBLASTGENES=$(ls cat_*.fa) # list Cat Gene FASTA files

for GENE in ${CBLASTGENES[@]}
  do
  echo "$GENE starting BLAST"
  blastn -query $Proj_PATH/CatResults/${GENE} -db $BDB_Path/lp23_plus_mt.fa -outfmt "6 qseqid sseqid sstart send length qcovhsp evalue" -out ${GENE/.fa/}.BLASTresults
  echo "$GENE BLAST finished"
done

## Move the BLASTresults to a new directory

mkdir BLASTresults

mv *.BLASTresults BLASTresults

```

## 2d - BLAST cat genes to Lynx discarded scaffolds

```{r  BLAST cat genes to Lynx discarded scaffolds, eval=FALSE, engine='bash'}

## Create BLAST database for discarded scaffold

cd $Data_PATH

mkdir Discarded_BLASTdatabase # create a directory for the Discarded Scaffold BLAST database

DiscBDB_PATH=/home/ebazzicalupo/Data/Discarded_BLASTdatabase # define path to Discarded Scaffold BLAST database

scp home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.discarded.scaffolds.fa $DiscBDB_PATH # copy Discarded Scaffold to the Discarded_BLASTdatabase directory

# create a BLAST database in the Discarded_BLASTdatabase directory
makeblastdb -in $DiscBDB_PATH/lp23.discarded.scaffolds.fa -parse_seqids -dbtype nucl


## BLAST each Cat Gene FASTA to the Lynx pardinus Discarded Scaffold BLAST database. Look at BLAST manual for output options.

cd $Proj_PATH/CatResults

CDSBLASTGENES=$(ls cat_*.fa) 

IFS=$'\n'

for GENE in ${CDSBLASTGENES[@]}
  do
  echo "$GENE starting BLAST"
  blastn -query $Proj_PATH/CatResults/${GENE} -db $DiscBDB_PATH/lp23.discarded.scaffolds.fa -outfmt "6 qseqid sseqid sstart send length qcovhsp evalue" -out ${GENE/.fa/}.DiscBLASTresults
  echo "$GENE BLAST finished"
  
done

## Move BLASTresults to new directory

mkdir DiscBLASTresults

mv *.DiscBLASTresults DiscBLASTresults

```

# 3. Search in Homo sapiens Genome Annotations for Genes not found in Lynx pardinus and Felis catus Genome Annotations. Extract corresponding sequence FASTA. Run BLAST to Lynx pardinus Reference Genome.

Repeat the search in Homo Sapiens genome annotations, using as input the empty results from the Felis catus search [step 3a]. This will give coordinates to specific regions in the Homo sapiens.
Use those coordinates to extract the corresponding sequence (.fa) from the Homo sapiens reference genome [step 3b], and BLAST it to the Lynx pardinus reference genome [step 3c]. Hit results from the BLAST will be analysed individually, to see if any genes in Lynx pardinus can be added to the Parent Gene ID list for further analyses [steps XX].

## 3a - Search in Human annotations

```{r Search in Human Annotations, eval=FALSE, engine='bash'}

cd $Proj_PATH

mkdir HumanResults # create directory to store the results for Homo sapiens

HUMANGENES=$(wc -l CatResults/*.gene.gff3 | grep ' 0 ' | cut -d '0' -f2 | sed 's/CatResults\/cat_//g' | sed 's/ //') # List empty results from Cat search

# for each gene create a gff3 file containing results and move it to HumanResults folder
for i in ${HUMANGENES[@]}
  do
  grep -i "${i/.gene.gff3/}" $Data_PATH/Homo_sapiens.GRCh38.92.gff3 > human_${i/.gene.gff3/}.gff3
  mv human_${i/.gene.gff3/}.gff3 HumanResults
done

```

## 3b - Generate Human gene FASTA files for BLAST

```{r Generate Human gene fasta files for BLAST, eval=FALSE, engine='bash'}

## Reference Genome FASTA files for Felis catus and Homo sapiens have been downloaded from the ensembl website (https://www.ensembl.org/info/data/ftp/index.html) and copied in the Data directory (/home/ebazzicalupo/Data).

cd $Proj_PATH/HumanResults

HUMANREFINE=$(ls human_*.gff3) # list results from grep search

# for each result from the grep search, create a gene.gff3 file with the non-gene (e.g. mRNA, CDS) strings removed
for i in ${HUMANREFINE[@]}
  do
  awk -v "key=gene" '$3 == key {print($0)}' ${i} > ${i/.gff3}.gene.gff3
done

HUMANcoords=$(ls human_*.gene.gff3) # list gene.gff3 files

# generate FASTA file for each gene.gff3 coordinates file
for i in ${HUMANcoords[@]}
  do
  bedtools getfasta -fo "${i/.gene.gff3}".fa -fi $Data_PATH/Homo_sapiens.GRCh38.dna_sm.toplevel.fa -bed ${i}
done

```

## 3c - BLAST human genes to Lynx genome

```{r  BLAST human genes to Lynx genome, eval=FALSE, engine='bash'}

## BLAST each Human Gene FASTA to the Lynx pardinus Reference Genome and BLAST database. Look at BLAST manual for output options.

cd $Proj_PATH/HumanResults

IFS=$'\n'

HBLASTGENES=$(ls human_*.fa) # list Human Gene FASTA files

for GENE in ${HBLASTGENES[@]}
  do
  echo "$GENE starting BLAST"
  blastn -query $Proj_PATH/HumanResults/${GENE} -db $BDB_Path/lp23_plus_mt.fa -outfmt "6 qseqid sseqid sstart send length qcovhsp evalue" -out ${GENE/.fa/}.BLASTresults
  echo "$GENE BLAST finished"
done

## Move the BLASTresults to a new directory

mkdir BLASTresults

mv *.BLASTresults BLASTresults

```

## 3d - BLAST human genes to Lynx discarded scaffolds

```{r  BLAST human genes to Lynx discarded scaffolds, eval=FALSE, engine='bash'}

## BLAST each Human Gene FASTA to the Lynx pardinus Discarded Scaffold BLAST database. Look at BLAST manual for output options.

cd $Proj_PATH/HumanResults

HDSBLASTGENES=$(ls human_*.fa) 

IFS=$'\n'

for GENE in ${HDSBLASTGENES[@]}
  do
  echo "$GENE starting BLAST"
  blastn -query $Proj_PATH/HumanResults/${GENE} -db $DiscBDB_PATH/lp23.discarded.scaffolds.fa -outfmt "6 qseqid sseqid sstart send length qcovhsp evalue" -out ${GENE/.fa/}.DiscBLASTresults
  echo "$GENE BLAST finished"
  
done

## Move BLASTresults to new directory

mkdir DiscBLASTresults

mv *.DiscBLASTresults DiscBLASTresults

```

# 4. Copy BLASTresults files from server to the laptop for consultation. Additional genes discovered during this step should be integrated to the ParentIDs.txt file before step 5

```{r  copy BLASTresults files from server to laptop, eval=FALSE, engine='bash'}

# cat greps
scp ebazzicalupo@genomics-b.ebd.csic.es:/home/ebazzicalupo/PelageGenes/CatResults/*.gff3 ~/home/ebazzicalupo/GrepResults

# cat coordinates
scp ebazzicalupo@genomics-b.ebd.csic.es:/home/ebazzicalupo/PelageGenes/CatResults/BLASTresults/cat_*.BLASTresults ~/home/ebazzicalupo/Results

# cat discaffold coordinates
scp ebazzicalupo@genomics-b.ebd.csic.es:/home/ebazzicalupo/PelageGenes/CatResults/DiscBLASTresults/* ~/home/ebazzicalupo/Results

# human greps
scp ebazzicalupo@genomics-b.ebd.csic.es:/home/ebazzicalupo/PelageGenes/HumanResults/*.gff3 ~/home/ebazzicalupo/GrepResults

# human coordinates
scp ebazzicalupo@genomics-b.ebd.csic.es:/home/ebazzicalupo/PelageGenes/Data/HumanResults/BLASTresults/human_*.BLASTresults ~/home/ebazzicalupo/Results

# human discaffold coordinates
scp ebazzicalupo@genomics-b.ebd.csic.es:/home/ebazzicalupo/PelageGenes/HumanResults/DiscBLASTresults/* ~/home/ebazzicalupo/Results

```

# 5. Generate a VCF with the list of SNPs of our genes of interest. 

First we need to divide the bigger VCF including both multiple species into one with only the species of interest (in this case divide Lynx lynx from Lynx pardinus). For this two alternative routs can be taken. One uses BCF tools [step 5a], which is very fast in running, but doesn't recalculate all of the statistics. The other uses GATK [step 5b], which is much slower, changes the order of the statistics in the INFO category (ANNOTATIONS goes in the middle instead of the end), but will recalculate all of the statistics. Both methods are based on a list of individuals to remove (changing the list you can divide by other parameters, like population).
Next we need to extract from the resulting VCF file the positions that fall within the genes we are interested in. This can also be done in two different ways. One uses BEDtools [step 5c], which uses as input files a BED file with the coordinates of the regions to extract [step 5b] and the VCF file. The limitation of this method is that it will not extract intergenic, upstream or downstream regions which might be of interest. The other method uses grep [step 5d], which will extract also these missing regions.

A new version of this step uses a different VCF file. This VCF is the one which includes both Lynx pardinus and Lynx lynx species, to include more information and allow comparisons between the two to be made. The different VCF file has been used directly in step 5d. The rest of the script was kept just in case it might be needed for future work.

## 5a - Divide VCF by species and remove no longer variable Sites - BCFtools

```{r  Divide VCF and remove no longer variable Sites, eval=FALSE, engine='bash'}

cd $gVCF_PATH # go to the gVCF files

## Using BCFtools - Problem with this is that it only recalculates the AN and AC fiels. Better use GATK (see next step)

declare SPECIES=$(ls {*lp,*ll}_*.g.vcf.gz | cut -c3-4 | sort | uniq) # list the abbreviations of the species we need to cut from our VCF

# For each species, add all individuals to a list of individuals to remove (list_to_remove.txt), create a VCF (-Ov) file selecting the individuals to remove from the list (-S), remove all non variable sites (min-ac 1:minor)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  ls *${i}*g.vcf.gz | cut -c1-12 > list_to_remove.txt
  bcftools view -S list_to_remove.txt --min-ac 1:minor -Ov -o $Proj_PATH/VCF/"${i}"_species.vcf $Proj_PATH/VCF/lp_bedIntersect_unique.vcf
  done
rm list_to_remove.txt

```

## 5b - Divide VCF by species and remove no longer variable Sites - GATK

```{r  Divide VCF with GATK, eval=FALSE, engine='bash'}

## Using GATK - This should recalculate ALL of the statistics for each species

# Copy of the reference genome in the Data folder
scp $LPRef_PATH $Data_PATH

# Create a FASTA dictionary (.dict) file for the reference genome for GATK to work
java -jar /home/tmp/Software/Picard/picard-tools-1.66/CreateSequenceDictionary.jar \
 R=$Data_PATH/lp23_plus_mt.fa \
 O=$Data_PATH/lp23_plus_mt.dict
 
# Create FASTA index (.fa.fai) file for the reference genome for GATK to work
samtools faidx $Data_PATH/lp23_plus_mt.fa

# Divide by species, create a screen for long GATK process

cd $Proj_PATH

screen -S GATK_devidebyspecies # create a screen to let GATK work while disconnected

Proj_PATH=/home/ebazzicalupo/PelageGenes # redefine path to the project directory

script $Proj_PATH/GATK_devidebyspecies.log # save script log

# Redefine variables for script
Proj_PATH=/home/ebazzicalupo/PelageGenes # path to the project directory
Data_PATH=/home/ebazzicalupo/Data # path to data directory
LPRef_PATH=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23_plus_mt.fa # path to lynx pardinus reference genome file
VCF_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/c_ll_lp_plus_h_ll_aafilled_SNPs_standard_filter.ann.vcf # path to annotated VCF file
gVCF_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/gVCFs # path to gVCFs
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar # path to GATK software

cd $gVCF_PATH

declare SPECIES=$(ls {*lp,*ll}_*.g.vcf.gz | cut -c3-4 | sort | uniq) # list the abbreviations of the species we need to cut from our VCF

for i in ${SPECIES[@]}
  do
  echo "${i}"
  ls *${i}*g.vcf.gz | cut -c1-12 > list_to_remove.txt
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $Data_PATH/lp23_plus_mt.fa \
  -V $Proj_PATH/VCF/c_ll_lp_plus_h_ll_aafilled_SNPs_standard_filter.ann.vcf \
  -o $Proj_PATH/VCF/"${i}"_GATK_species.vcf \
  --sample_file list_to_remove.txt \
  --preserveAlleles \
  --excludeNonVariants
done

rm list_to_remove.txt

```

## 5b - Create BED from ParentIDs and edit it to be compatible with the VCF

```{r  Create BED from ParentIDs and edit for compatibility, eval=FALSE, engine='bash'}

cd $Proj_PATH

# Create GFF3 file by looking for ParentIDs in Lynx Genome Annotations
grep -f ParentIDs.txt $Data_PATH/LYPA23C.all.fix.gff3 > Candidate.gff3

# Create BED file from the GFF3 with the following tab separated columns: scaffold, start, end, type, info
cut -f1,3,4,5,9 Candidate.gff3 | awk 'BEGIN {FS="\t"; OFS="\t"} {print $1, $3, $4, $2, $5}' > Candidate.bed

# Modify BED to allow VCF compatibility (scaffold name matching) - sort and insert a . at 4th character in each line
sort -k1,2 Candidate.bed | awk -vFS="" -vOFS="" '{$4=$4"."}1' > Candidate.compatible.bed

```

## 5c - Intersect compatible BED with the annotated VCF and remove repetitions generated by the overlapping regions in the BED file

```{r  Intersect BED with the VCF and remove repetitions, eval=FALSE, engine='bash'}

## Intersect BED with the VCF

cd $Proj_PATH

mkdir VCF # Create directory for VCF results

# Intersect the VCF file with the compatible BED
bedtools intersect -header -a $VCF_PATH -b Candidate.compatible.bed > $Proj_PATH/VCF/lp_bedIntersect.vcf

## Remove duplicates from the Intersect file

cd $Proj_PATH/VCF

grep "#" lp_bedIntersect.vcf > lp_bedIntersect_unique.vcf # copy header part

grep -v "#" lp_bedIntersect.vcf | sort -u -k1,2 >> lp_bedIntersect_unique.vcf # copy table, remove duplicates, add it to header

```

## 5d - ALTERNATIVE: look for (grep) ParentIDs in VCF file directly

```{r  Grep ParentIDs from VCF, eval=FALSE, engine='bash'}

## Prepare ParentIDs file for grep
cd $Proj_PATH

# The ParentIDs list contains "Parent=" before each ID, interfering with the search. 
sed 's/Parent=//g' ParentIDs.txt > ParentIDs_onlyIDs.txt

# Add the '#' sign to the list in order to copy the header part of the VCF too
nano ParentIDs_onlyIDs.txt


## Grep with VCF divided by species (from previous steps)

# Grep all elements in the ParentIDs list from the VCF
grep -f $Proj_PATH/ParentIDs_onlyIDs.txt $Proj_PATH/VCF/lp_GATK_species.vcf > $Proj_PATH/VCF/lp_GATK_ParentIDsGrep.vcf

# Sort SNPs
sort -k1,2 $Proj_PATH/VCF/lp_GATK_ParentIDsGrep.vcf > tmp && mv tmp $Proj_PATH/VCF/lp_GATK_ParentIDsGrep.vcf


## Grep with annotated VCF file including both species

cd $Proj_PATH/VCF

# A copy of the VCF file including both species has been copied in $Proj_PATH/VCF

scp /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/c_ll_lp_plus_h_ll_polarized.lr_ann.vcf $Proj_PATH/VCF

# Grep all elements in the ParentIDs list from the VCF

grep -f $Proj_PATH/ParentIDs_onlyIDs.txt $Proj_PATH/VCF/c_ll_lp_plus_h_ll_polarized.lr_ann.vcf > $Proj_PATH/VCF/c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep.vcf

# Sort SNPs
sort -k1,2 $Proj_PATH/VCF/c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep.vcf > tmp && mv tmp $Proj_PATH/VCF/c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep.vcf

```

# 6. Create a table with the useful SNPs information and annotations from VCF file

A table is created with the information regarding the SNPs. Different approaches have been tried. The final version [step 6a] has the advantage of having a fixed number of columns for the SNPEFF annotations (the maximum present in the file, with the ones missing filled with NONE), and a unique column for all of the CUSTOM annotations containing the information regarding the "feature" (region where the SNP falls). SNPs with no CUSTOM annotation will have "EMPTY" in that column.

A table from the VCF file contaning information for both species (see step 5d) also has been generated [step 6b and 6c]. The change to a larger dataset (VCF contaning unfiltered positions for both L.pardinus and L.lynx), has generated numerous problems not encountered before, especially on the final table. Version 6c (Final) of the script tries to solve most of them by simplifying the final result. It has the advantage of having a single column for SNPEFF annotations, which with a larger dataset are also more numerous. All of the statistics in 6c version have been removed for increased clarity, leaving only the information regarding the Ancestral Allel and the Annotation.

## 6a - Create a table with the useful SNPs information and annotations from per species divided VCF file

```{r Create a table with the useful SNPs information and annotations, eval=FALSE, engine='bash'}

## FINAL VERSION - fixed number of SNPEFF and Custom annotations for each SNP: divide the table in two - one with SNPEFF only and other with custom only, then unite them

# remove header and information about individuals
grep -v '#' lp_GATK_ParentIDsGrep.vcf | cut -f1-8 > lp_GATK_ParentIDsGrep_noIndividuals.vcf

# replace blank spaces in annotations with "na"
sed 's/||/|na|/g' lp_GATK_ParentIDsGrep_noIndividuals.vcf | sed 's/||/|na|/g' > lp_GATK_ParentIDsGrep_noIndividuals_nas.vcf

# move the ANN= column to the end of the file - ONLY IF THE VCF HAS BEEN SEPARATED USING GATK WHICH REORDERS THE STATISTICS
awk -v FS=';' -v OFS=';' '{print $1,$2,$3,$4,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16,$5}' lp_GATK_ParentIDsGrep_noIndividuals_nas.vcf > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered.vcf

# remove custom annotations - SNPEFF annotations ONLY are left
sed 's/,.*|custom|MODIFIER|na|na|CUSTOM&LYPA23C|.*|na|na|na|na|na|//g' lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered.vcf > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustom.vcf

# add "NONE" to missing ANN columns to render the file squared for NOCUSTOM FILE
max=$(awk -v FS=',' 'max < NF { max = NF } END { print max }' lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustom.vcf)

echo $max # to know how many columns of SNPEFF annotations there will be

awk -v max=$max -v FS=',' -v OFS=',' '{ for(i=NF+1; i<=max; i++) $i = "NONE"; print }' lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustom.vcf > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustomsquared.vcf

# isolate custom annotations - CUSTOM annotations ONLY are left

# get all lines with custom annotations and the corresponding line number - CUSTOM ONLY
grep -n -o ",.|custom|MODIFIER|na|na|CUSTOM&LYPA23C|.*|na|na|na|na|na|" lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered.vcf > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly.vcf

# generate a file with the corresponding line number for the custom annotations - CUSTOM ONLY
cut -d ':' -f1 lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly.vcf > aa_customlines

# generate a file with all the numbers from 1 to the maximum line number (total number of lines in the original file)
TotalNumberOfLines=$(grep "lp" lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered.vcf | wc -l)

seq $TotalNumberOfLines > aa_totlines

# subtract the custom line numbers from the total number of lines to generate a file listing the missing lines (lines with no custom annotation)
comm aa_customlines aa_totlines | cut -f2 | sed '/^\s*$/d' > aa_nocustomlines

# add a white line in the CUSTOM ONLY annotations file in the missing lines - CAREFUL AS IT OVERWRITES - CHECK IF DONE ALREADY / OTHER POSSIBLE PROBLEMS - if problems are found better re-generate lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly.vcf from scratch
NoCustomLines=$(cat aa_nocustomlines)

for i in $NoCustomLines
  do
  ed -s lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly.vcf < <(printf '%s\n' ${i}i "" . wq)
done

# remove useless files used for previous steps
rm aa_*

# remove comma before pasting the two tables together - CUSTOM ONLY
cut -d ':' -f2 lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly.vcf | sed 's/,//' > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly_blanklines.vcf

# condense all information in unique custom column: first count the maximum number of custom annotation columns (max); then cut columns 7, 22, 37, 52, 67 ecc. (always add 15 to the previous starting from 7) a number of times equal to max (to catch all) - CUSTOM ONLY

max=$(awk -v FS=',' 'max < NF { max = NF } END { print max }' lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly_blanklines.vcf) && echo $max # count number of columns to include

cut -d '|' -f7,22,37,52 lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly_blanklines.vcf > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly_blanklines_condensed.vcf # in this case max=4 so columns 7,22(7+15),37(7+30),52(7+45)

# insert EMPTY in empty lines CUSTOM ONLY
sed -i -e 's/^$/EMPTY/' lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly_blanklines_condensed.vcf

# paste together the SNPEFF ONLY and the CUSTOM ONLY files
paste -d ',' lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustomsquared.vcf lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_customonly_blanklines_condensed.vcf > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustomsquared_custom.vcf

# remove other separators -> leave TAB as only separator
tr ';' '\t' <lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustomsquared_custom.vcf | tr ',' '\t' > lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustomsquared_custom_tabs.vcf

# remove the "variable"= before of the variable value
grep 'INFO=' lp_GATK_ParentIDsGrep.vcf | cut -d '=' -f3 | cut -d ',' -f1 > info.txt

while read pattern
do
sed 's/'$pattern'=//' lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustomsquared_custom_tabs.vcf > tmp
mv tmp lp_GATK_ParentIDsGrep_noIndividuals_nas_ordered_nocustomsquared_custom_tabs.vcf
done < info.txt

rm info.txt

# header will need to be added by hand (not all INFO is present in file and adding it all to the headers will mean having mismatching variable-value couples). The ones present in the file are CHROM	POS	ID	REF	ALT	QUAL	FILTER	AA	AC	AF	AN	BaseQRankSum	ClippingRankSum	DP	ExcessHet	FS	InbreedingCoeff	MQ	MQRankSum	QD	ReadPosRankSum	SOR	SNPEFF1	SNPEFF2	CUSTOM (number of SNPEFF columns can be seen by echoing $max while squaring the table)
touch headers.txt
nano headers.txt

```

## 6b - Create a table with the useful SNPs information and annotations lp and ll annotated VCF file

```{r Create a table with the useful SNPs information and annotations, eval=FALSE, engine='bash'}

## FINAL VERSION - fixed number of SNPEFF and Custom annotations for each SNP: divide the table in two - one with SNPEFF only and other with custom only, then unite them

# remove header and information about individuals
grep -v '#' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep.vcf | cut -f1-8 > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals.vcf

# replace blank spaces in annotations with "na"
sed 's/||/|na|/g' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals.vcf | sed 's/||/|na|/g' > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas.vcf

# remove custom annotations - SNPEFF annotations ONLY are left
sed 's/|,.*|custom|MODIFIER|na|na|CUSTOM&LYPA23C|.*|na|na|na|na|na|/|/g' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustom.vcf

# add "NONE" to missing ANN columns to render the file squared for NOCUSTOM FILE
max=$(awk -v FS='|,' 'max < NF { max = NF } END { print max }' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustom.vcf)

echo $max # to know how many columns of SNPEFF annotations there will be

awk -v max=$max -v FS=',' -v OFS=',' '{ for(i=NF+1; i<=max; i++) $i = "NONE"; print }' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustom.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustomsquared.vcf

# isolate custom annotations - CUSTOM annotations ONLY are left

# get all lines with custom annotations and the corresponding line number - CUSTOM ONLY
grep -n -o ",.|custom|MODIFIER|na|na|CUSTOM&LYPA23C|.*|na|na|na|na|na|" c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_ordered.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly.vcf

# generate a file with the corresponding line number for the custom annotations - CUSTOM ONLY
cut -d ':' -f1 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly.vcf > aa_customlines

# generate a file with all the numbers from 1 to the maximum line number (total number of lines in the original file)
TotalNumberOfLines=$(grep "lp" c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_ordered.vcf | wc -l)

seq $TotalNumberOfLines > aa_totlines

# subtract the custom line numbers from the total number of lines to generate a file listing the missing lines (lines with no custom annotation)
comm aa_customlines aa_totlines | cut -f2 | sed '/^\s*$/d' > aa_nocustomlines

# add a white line in the CUSTOM ONLY annotations file in the missing lines - CAREFUL AS IT OVERWRITES - CHECK IF DONE ALREADY / OTHER POSSIBLE PROBLEMS - if problems are found better re-generate c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly.vcf from scratch
NoCustomLines=$(cat aa_nocustomlines)

for i in $NoCustomLines
  do
  ed -s c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly.vcf < <(printf '%s\n' ${i}i "" . wq)
done

# remove useless files used for previous steps
rm aa_*

# remove comma before pasting the two tables together - CUSTOM ONLY
cut -d ':' -f2 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly.vcf | sed 's/,//' > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly_blanklines.vcf

# condense all information in unique custom column: first count the maximum number of custom annotation columns (max); then cut columns 7, 22, 37, 52, 67 ecc. (always add 15 to the previous starting from 7) a number of times equal to max (to catch all) - CUSTOM ONLY

max=$(awk -v FS=',' 'max < NF { max = NF } END { print max }' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly_blanklines.vcf) && echo $max # count number of columns to include

cut -d '|' -f7,22,37,52 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly_blanklines.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly_blanklines_condensed.vcf # in this case max=4 so columns 7,22(7+15),37(7+30),52(7+45)

# insert EMPTY in empty lines CUSTOM ONLY
sed -i -e 's/^$/EMPTY/' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly_blanklines_condensed.vcf

# paste together the SNPEFF ONLY and the CUSTOM ONLY files
paste -d ',' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustomsquared.vcf c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_customonly_blanklines_condensed.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustomsquared_custom.vcf

# remove other separators -> leave TAB as only separator
tr ';' '\t' <c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustomsquared_custom.vcf | tr ',' '\t' > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustomsquared_custom_tabs.vcf

# remove the "variable"= before of the variable value
grep 'INFO=' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep.vcf | cut -d '=' -f3 | cut -d ',' -f1 > info.txt

while read pattern
do
sed 's/'$pattern'=//' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustomsquared_custom_tabs.vcf > tmp
mv tmp c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_nocustomsquared_custom_tabs.vcf
done < info.txt

rm info.txt

# header will need to be added by hand (not all INFO is present in file and adding it all to the headers will mean having mismatching variable-value couples). The ones present in the file are CHROM	POS	ID	REF	ALT	QUAL	FILTER	AA	AC	AF	AN	BaseQRankSum	ClippingRankSum	DP	ExcessHet	FS	InbreedingCoeff	MQ	MQRankSum	QD	ReadPosRankSum	SOR	SNPEFF1	SNPEFF2	CUSTOM (number of SNPEFF columns can be seen by echoing $max while squaring the table)
touch headers.txt
nano headers.txt

```

## 6c - AGAIN Create a table with the useful SNPs information and annotations lp and ll annotated VCF file

```{r Create a table with the useful SNPs - Section 1, eval=FALSE, engine='bash'}

## Section 1: Preprocess and divide in NoAnnotations, SNPEFF annotations and CUSTOM annotations

# remove header and information about individuals
grep -v '#' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep.vcf | cut -f1-8 > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals.vcf

# replace blank spaces in annotations with "na"
sed 's/||/|na|/g' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals.vcf | sed 's/||/|na|/g' > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas.vcf

# separate annotations from rest of VCF

awk -F ';ANN='  '{print $1}' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_noann.vcf

awk -F 'ANN='  '{print $2}' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly.vcf

# Remove Custom annotations - SNPEFF annotations ONLY are LEFT
sed 's/,.*|custom|MODIFIER|na|na|CUSTOM&LYPA23C|.*|na|na|na|na|na|//g' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff.vcf

# Remove Loss of Function (LOF) from SNPEFF only
sed 's/;LOF.*)//g' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof.vcf

# get all lines with LOF and their line number - LOF ONLY are LEFT
grep -n -o ";LOF.*)" c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf

# get all lines with custom annotations and the corresponding line number - CUSTOM annotations ONLY are LEFT
grep -n -o ",.|custom|MODIFIER|na|na|CUSTOM&LYPA23C|.*|na|na|na|na|na|" c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly.vcf

```

## SNPEFF

```{r Create a table with the useful SNPs - Section 2, eval=FALSE, engine='bash'}

## Section 2: Generate a SNPEFF columns file with SNPEFF annotations decomposed for each line

# Make all of SNPEFF annotations have same number of fields (16 normally, 15 if it's the last annotation on the line without warning messages)

sed 's/|,/|na,/g' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof.vcf | sed 's/,/|,/g' > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf

# count maximum number of SNPEFF annotations

max=$(awk -v FS=',' 'max < NF { max = NF } END { print max }' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf ) && echo $max # count number of columns to include -> in this case 16.

# (column 2) get ANNOTATION information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the second)
cut -d '|' -f2,18,34,50,66,82,98,114,130,146,162,178 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_annotation

# (column 3) get IMPACT information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the third)
cut -d '|' -f3,19,35,51,67,83,99,115,131,147,163,179 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_impact

# (column 5) get GENE ID information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the fifth)
cut -d '|' -f5,21,37,53,69,85,101,117,133,149,165,181 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_geneID

# (column 6) get FEATURE TYPE information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the sixth)
cut -d '|' -f6,22,38,54,70,86,102,118,134,150,166,182 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_featuretype

# (column 7) get FEATURE ID information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the seventh)
cut -d '|' -f7,23,39,55,71,87,103,119,135,151,167,183 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_featureID

# (column 8) get BIOTYPE information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the eitghth)
cut -d '|' -f8,24,40,56,72,88,104,120,136,152,168,184 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n'  > Snpeff_biotype

# (column 9) get intron/exon RANK / TOTAL information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the ninth)
cut -d '|' -f9,25,41,57,73,89,105,121,137,153,169,185 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_rank

# (column 10) get HGVS variant information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the tenth)
cut -d '|' -f10,26,42,58,74,90,106,122,138,154,170,186 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_hgvsvar

# (column 11) get HGVSprotein variant information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the eleventh)
cut -d '|' -f11,27,43,59,75,91,107,123,139,155,171,187 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_protvar

# (column 12) get cDNA POS/LENGTH information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the twelth)
cut -d '|' -f12,28,44,60,76,92,108,124,140,156,172,188 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_cdnapos

# (column 13) get CDS POS/LENGTH information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the thirteenth)
cut -d '|' -f13,29,45,61,77,93,109,125,141,157,173,189 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_cdspos

# (column 14) get PROTEIN POS/LENGTH information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the fourteenth)
cut -d '|' -f14,30,46,62,78,94,110,126,142,158,174,190 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_protpos

# (column 15) get DISTANCE TO FEATURE information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the fifteenth)
cut -d '|' -f15,31,47,63,79,95,111,127,143,159,175,191 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_featdist

# (column 16) get ERRORS information - Having 16 fields of snpeff annotations we get every 16th column starting from the column of interest (in this case the sixteenth)
cut -d '|' -f16,32,48,64,80,96,112,128,144,160,176,192 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nolof_equalfields.vcf | sed 's/|na|//g' | sed 's/na|//g' | sed 's/|na//g' | sed 's/na//g' | sed -e 's/^$/NA/' | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Snpeff_errors

# paste everything together
paste Snpeff_annotation Snpeff_impact Snpeff_geneID Snpeff_featuretype Snpeff_featureID Snpeff_biotype Snpeff_rank Snpeff_hgvsvar Snpeff_protvar Snpeff_cdnapos Snpeff_cdspos Snpeff_protpos Snpeff_featdist Snpeff_errors > SNPEFF_COMPLETE

# remove intermediate files
rm Snpeff_*

```

## CUSTOM

```{r Create a table with the useful SNPs - Section 3, eval=FALSE, engine='bash'}

## Section 3: Condense all of Custom Annotations into one column and add blank lines for positions missing Custom annotations

# generate a file with the corresponding line number for the custom annotations - CUSTOM ONLY
cut -d ':' -f1 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly.vcf > aa_customlines

# generate a file with all the numbers from 1 to the maximum line number (total number of lines in the original file)
TotalNumberOfLines=$(grep "lp" c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas.vcf | wc -l)

seq $TotalNumberOfLines > aa_totlines

# subtract the custom line numbers from the total number of lines to generate a file listing the missing lines (lines with no custom annotation)
comm aa_customlines aa_totlines | cut -f2 | sed '/^\s*$/d' > aa_nocustomlines # NOT WORKING ON SERVER -> copied aa_customlines and aa_totlines to my laptop, executed this command there and then copied aa_nocustomlines back to server - ACTUALLY it probably worked, done it on laptop just to be sure


# add a white line in the CUSTOM ONLY annotations file in the missing lines - CAREFUL AS IT OVERWRITES - CHECK IF DONE ALREADY / OTHER POSSIBLE PROBLEMS - if problems are found better re-generate c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly.vcf from scratch
NoCustomLines=$(cat aa_nocustomlines)

for i in $NoCustomLines
  do
  awk -v n=${i} -v s="" 'NR == n {print s} {print}' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly.vcf > tmp && mv tmp c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly.vcf
done

# remove useless files used for previous steps
rm aa_*

# remove comma and line number before pasting the two tables together - CUSTOM ONLY
cut -d ':' -f2 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly.vcf | sed 's/,//' > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly_blanklines.vcf

# condense all information in unique custom column: first count the maximum number of custom annotation columns (max); then cut columns 7, 22, 37, 52, 67 ecc. (always add 15 to the previous starting from 7) a number of times equal to max (to catch all) - CUSTOM ONLY

max=$(awk -v FS=',' 'max < NF { max = NF } END { print max }' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly_blanklines.vcf) && echo $max # count number of columns to include

cut -d '|' -f7,22,37,52,67,82,97,112,127,142,157,172 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly_blanklines.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly_blanklines_condensed.vcf # in this case max=12 so columns 7,22(7+15),37(7+30),52(7+45),67,82,97,112,127,142,157,172

# insert EMPTY in empty lines and remove repetitions CUSTOM ONLY
sed -e 's/^$/EMPTY/' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly_blanklines_condensed.vcf | sed 's/|/ /g' | sed ':s;s/\(\<\S*\>\)\(.*\)\<\1\>/\1\2/g;ts;s/  */ /g' | sed 's/ /|/g' | tr '\n' ' ' | sed 's/| / /g' | tr ' ' '\n' > Custom_ONLY

```

## LOF

```{r Create a table with the useful SNPs - Section 4, eval=FALSE, engine='bash'}

## Section 4: Create column for Loss of Function Annotations (LOF)

# generate a file with the corresponding line number for the LOF annotations - LOF ONLY
cut -d ':' -f1 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf > aa_loflines

# generate a file with all the numbers from 1 to the maximum line number (total number of lines in the original file)
TotalNumberOfLines=$(cat c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas.vcf | wc -l)

seq $TotalNumberOfLines > aa_totlines

# subtract the custom line numbers from the total number of lines to generate a file listing the missing lines (lines without LOF annotations)
grep -F -x -v -f aa_loflines aa_totlines > aa_noloflines

# add a white line in the LOF ONLY annotations file in the missing lines - CAREFUL AS IT OVERWRITES - CHECK IF DONE ALREADY / OTHER POSSIBLE PROBLEMS - if problems are found better re-generate c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf from scratch -> VERY SLOW better run it on a screen
NoLOFLines=$(cat aa_noloflines)
echo "" >> c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf # add one empty line at the end of the file so that the script will fill all empty spaces
for i in $NoLOFLines
  do
  awk -v n=${i} -v s="" 'NR == n {print s} {print}' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf > tmp && mv tmp c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf
done

sed '$d' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf > tmp && mv tmp c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf # remove the empty line previously added

# remove comma, remove line number, add NA to empty columns before pasting the two tables together - CUSTOM ONLY
cut -d ':' -f2 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_lofonly.vcf | sed 's/,//' | sed -e 's/^$/NA/' > LOF_annotations

```

## PASTING

```{r Create a table with the useful SNPs - Section 5, eval=FALSE, engine='bash'}

## Section 5: Paste all tables together


# paste SNPEFF ONLY (c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_snpeff_nocomma.vcf) and CUSTOM ONLY (c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_annonly_customonly_blanklines_condensed.vcf) tables together

paste -d '\t' Custom_ONLY SNPEFF_COMPLETE LOF_annotations > ALL_Annotations


# BEFORE PASTING THE NO ANNOTATIONS FILE NEEDS MODIFICATIONS - keep only AA information

cut -d ';' -f1 c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_noann.vcf > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_noann_aainfoonly.vcf


# paste annotations to table without no annotations table

paste -d '\t' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_noIndividuals_nas_noann_aainfoonly.vcf ALL_Annotations > c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_squaredtable.vcf


# Final adjustments to table

# Remove "AA=" before the AA

sed 's/AA=//' c_ll_lp_plus_h_ll_polarized.lr_ann.ParentIDsGrep_squaredtable.vcf > PelageGenesTable.vcf

# HEADER
SCAFFOLD	POS	ID	REF	ALT	QUAL	FILTER	AA	CUSTOM	SNPEFF	IMPACT	GENE_ID	FEATURE	FEATURE_ID	BIOTYPE	RANK	VARIANT	P_VARIANT	CDNA_POS	CDS_POS	PROT_POS	DISTANCE	ERRORS  LOF

```
